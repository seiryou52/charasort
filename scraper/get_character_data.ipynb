{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6614910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1cf03",
   "metadata": {},
   "source": [
    "* Assumes wiki is gold standard source of truth and relies on its page structure, chronology, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bc3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://toarumajutsunoindex.fandom.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5dddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 'Toaru_Majutsu_no_Index'\n",
    "RAILGUN = 'Toaru_Kagaku_no_Railgun'\n",
    "ASTRAL_BUDDY = 'Astral_Buddy'\n",
    "ACCEL = 'Toaru_Kagaku_no_Accelerator'\n",
    "DARK_MATTER = 'Toaru_Kagaku_no_Dark_Matter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5799ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_data(wiki_url, affiliation):\n",
    "        \n",
    "    data = {\n",
    "        'name_en': '',\n",
    "        'name_jp': '',\n",
    "        'img_url': '',\n",
    "        'affiliation': [affiliation],\n",
    "        'series': [],\n",
    "        'is_supporting_character': False\n",
    "    }\n",
    "    \n",
    "    soup = BeautifulSoup(requests.get(wiki_url).text, 'html.parser')\n",
    "    name_en = soup.select('h1.page-header__title')[0].text\n",
    "    name_jp_raw = soup.find(\"div\", {\"data-source\": \"Kanji\"})\n",
    "    \n",
    "    # only get characters with both japanese and english names\n",
    "    if not name_jp_raw:\n",
    "        return None\n",
    "    \n",
    "    data['name_en'] = name_en\n",
    "    data['name_jp'] = name_jp_raw.find(\"div\", {\"class\": \"pi-data-value pi-font\"}).text\n",
    "    \n",
    "    # default image\n",
    "    default_img_url = soup.find(\"a\", {\"class\": \"image-thumbnail\"}).get('href')\n",
    "    data['img_url'] = default_img_url\n",
    "    \n",
    "    headlines = [_['id'] for _ in soup.select(\"span.mw-headline\")]\n",
    "    for headline in headlines:\n",
    "        if INDEX in headline:\n",
    "            data['series'].append('禁書')\n",
    "        elif RAILGUN in headline:\n",
    "            data['series'].append('超電磁砲')\n",
    "        elif ASTRAL_BUDDY in headline:\n",
    "            data['series'].append('アストラル・バディ')\n",
    "        elif ACCEL in headline:\n",
    "            data['series'].append('一方通行')\n",
    "        elif DARK_MATTER in headline:\n",
    "            data['series'].append('未元物質')\n",
    "\n",
    "    # ignore characters that are not in any of the main series/spinoffs\n",
    "    if not data['series']:\n",
    "        return None\n",
    "        \n",
    "    #data['is_supporting_character'] = not any(\n",
    "    #    [\"background\" in _.text.strip().lower() for _ in soup.select('span.toctext')]\n",
    "    #)\n",
    "    \n",
    "    data['is_supporting_character'] = soup.find('div', {'id': 'stub'}) is not None\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb56ce",
   "metadata": {},
   "source": [
    "* Affiliation (magic/science/other) based on wiki categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dafa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'magic': {\n",
    "        'path': '/wiki/Category:Magic_Side_Characters',\n",
    "        'char_urls': []\n",
    "    },\n",
    "    'science': {\n",
    "        'path': '/wiki/Category:Science_Side_Characters',\n",
    "        'char_urls': []\n",
    "    },\n",
    "    'other': {\n",
    "        'path': '/wiki/Category:Normal_Characters',\n",
    "        'char_urls': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3509c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_pages(url, char_urls=None):\n",
    "    if char_urls is None:\n",
    "        char_urls = []\n",
    "    \n",
    "    curr_page = requests.get(url, allow_redirects=False)\n",
    "    assert(curr_page.status_code == 200)\n",
    "    \n",
    "    curr_soup = BeautifulSoup(curr_page.text, 'html.parser')\n",
    "    \n",
    "    # only get characters with pictures\n",
    "    curr_char_divs = [\n",
    "        div.find('a') for div in curr_soup.find_all(\"div\", {\"class\": \"category-page__member-left\"})\n",
    "        if 'Template_Placeholder_other.png' not in str(div)\n",
    "    ]\n",
    "    curr_char_divs = [d for d in curr_char_divs if d]\n",
    "\n",
    "    # only get characters with valid pages (& no redirects)\n",
    "    for curr_char_div in curr_char_divs:\n",
    "        curr_char_url = \"{base}{suffix}\".format(base=base_url, suffix=curr_char_div.get('href'))\n",
    "        is_valid_page = requests.get(curr_char_url, allow_redirects=False).status_code == 200\n",
    "        if not is_valid_page:\n",
    "            continue\n",
    "        char_urls.append(curr_char_url)\n",
    "\n",
    "    next_page = curr_soup.find(\"a\", {\"class\": \"category-page__pagination-next\"})\n",
    "    if next_page:\n",
    "        next_url = next_page.get(\"href\")\n",
    "        char_urls.extend(get_character_pages(next_url, char_urls))\n",
    "        \n",
    "    return char_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6f6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, _ in categories.items():\n",
    "    category_url = base_url + _['path']\n",
    "    categories[name]['char_urls'] = get_character_pages(category_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f46e6",
   "metadata": {},
   "source": [
    "Get data\n",
    "\n",
    "* Deal format is array of characters\n",
    "* Target json - [{name:\"name\", img: \"img.png\", opts: {series:[\"a\"], affiliation:[\"b\"]}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bb97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = dict()\n",
    "\n",
    "for category, _ in categories.items():\n",
    "    for char_url in _['char_urls']:\n",
    "        data = defaultdict(list)\n",
    "        curr_data = get_character_data(char_url, category)\n",
    "        if not curr_data:\n",
    "            continue\n",
    "            \n",
    "        name = \"{jp} ({en})\".format(jp=curr_data['name_jp'], en=curr_data['name_en'])\n",
    "        \n",
    "        data['img'] = re.search('latest\\?cb=(.+)', curr_data['img_url'], re.IGNORECASE).group(1)\n",
    "        #data['img'] = curr_data['img_url']\n",
    "        data['affiliation'].extend(curr_data['affiliation'])\n",
    "        data['series'].extend(curr_data['series'])\n",
    "        data['is_supporting_character'] = curr_data['is_supporting_character']\n",
    "        \n",
    "        data['affiliation'] = list(set(data['affiliation']))\n",
    "        data['series'] = list(set(data['series']))\n",
    "        \n",
    "        \n",
    "        characters[name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a492f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "\n",
    "for character in characters:\n",
    "    curr = characters[character]\n",
    "    output_data.append(\n",
    "        dict(\n",
    "            name = character,\n",
    "            img = curr['img'],\n",
    "            opts = dict(\n",
    "                series=curr['series'], \n",
    "                affiliation=curr['affiliation'], \n",
    "                is_supporting_character=curr['is_supporting_character']\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27d2545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual updates\n",
    "for i, x in enumerate(output_data):\n",
    "    if any(n in x['name'] for n in ['Misaka Mikoto', 'Shokuhou Misaki', 'Shirai Kuroko']):\n",
    "        if \"アストラル・バディ\" not in x['opts']['series']:\n",
    "            output_data[i]['opts']['series'].append(\"アストラル・バディ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6bde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27131011",
   "metadata": {},
   "source": [
    "Ended up downloading the images using wget ._.\n",
    "\n",
    "To preserve aspect ratio, the downloaded images were resized and padded instead. See the other notebook in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23aaf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('img.txt', 'w') as f:\n",
    "#    for _ in output_data:\n",
    "#        f.write(_['img'])\n",
    "#        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaa839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
