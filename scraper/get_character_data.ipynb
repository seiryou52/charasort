{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6614910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import json\n",
    "#import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1cf03",
   "metadata": {},
   "source": [
    "* Assumes wiki is gold standard source of truth and relies on its page structure, chronology, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bc3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://toarumajutsunoindex.fandom.com'\n",
    "#img_root = 'https://static.wikia.nocookie.net/to-aru-majutsu-no-index/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5dddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 'Toaru_Majutsu_no_Index'\n",
    "RAILGUN = 'Toaru_Kagaku_no_Railgun'\n",
    "ASTRAL_BUDDY = 'Astral_Buddy'\n",
    "ACCEL = 'Toaru_Kagaku_no_Accelerator'\n",
    "DARK_MATTER = 'Toaru_Kagaku_no_Dark_Matter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5799ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_data(wiki_url, affiliation):\n",
    "        \n",
    "    data = {\n",
    "        'name_en': '',\n",
    "        'name_jp': '',\n",
    "        'img_url': '',\n",
    "        'affiliation': [affiliation],\n",
    "        'series': []\n",
    "    }\n",
    "    \n",
    "    soup = BeautifulSoup(requests.get(wiki_url).text, 'html.parser')\n",
    "    name_en = soup.select('h1.page-header__title')[0].text\n",
    "    name_jp_raw = soup.find(\"div\", {\"data-source\": \"Kanji\"})\n",
    "    \n",
    "    # only get characters with both japanese and english names\n",
    "    if not name_jp_raw:\n",
    "        return None\n",
    "    \n",
    "    data['name_en'] = name_en\n",
    "    data['name_jp'] = name_jp_raw.find(\"div\", {\"class\": \"pi-data-value pi-font\"}).text\n",
    "    \n",
    "    # default image\n",
    "    default_img_url = soup.find(\"a\", {\"class\": \"image-thumbnail\"}).get('href')\n",
    "    data['img_url'] = default_img_url\n",
    "    \n",
    "    headlines = [_['id'] for _ in soup.select(\"span.mw-headline\")]\n",
    "    for headline in headlines:\n",
    "        if INDEX in headline:\n",
    "            #data['series'].append('禁書')\n",
    "            data['series'].append('I')\n",
    "        elif RAILGUN in headline:\n",
    "            #data['series'].append('超電磁砲')\n",
    "            data['series'].append('R')\n",
    "        elif ASTRAL_BUDDY in headline:\n",
    "            #data['series'].append('アストラル・バディ')\n",
    "            data['series'].append('AB')\n",
    "        elif ACCEL in headline:\n",
    "            #data['series'].append('一方通行')\n",
    "            data['series'].append('AC')\n",
    "        elif DARK_MATTER in headline:\n",
    "            #data['series'].append('未元物質')\n",
    "            data['series'].append('DM')\n",
    "            \n",
    "    # ignore characters that are not in any of the main series/spinoffs\n",
    "    if not data['series']:\n",
    "        return None\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb56ce",
   "metadata": {},
   "source": [
    "* Affiliation (magic/science/other) based on wiki categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dafa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'magic': {\n",
    "        'path': '/wiki/Category:Magic_Side_Characters',\n",
    "        'char_urls': []\n",
    "    },\n",
    "    'science': {\n",
    "        'path': '/wiki/Category:Science_Side_Characters',\n",
    "        'char_urls': []\n",
    "    },\n",
    "    'other': {\n",
    "        'path': '/wiki/Category:Normal_Characters',\n",
    "        'char_urls': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3509c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_pages(url, char_urls=None):\n",
    "    if char_urls is None:\n",
    "        char_urls = []\n",
    "    \n",
    "    curr_page = requests.get(url, allow_redirects=False)\n",
    "    assert(curr_page.status_code == 200)\n",
    "    \n",
    "    curr_soup = BeautifulSoup(curr_page.text, 'html.parser')\n",
    "    \n",
    "    # only get characters with pictures\n",
    "    curr_char_divs = [\n",
    "        div.find('a') for div in curr_soup.find_all(\"div\", {\"class\": \"category-page__member-left\"})\n",
    "        if 'Template_Placeholder_other.png' not in str(div)\n",
    "    ]\n",
    "    curr_char_divs = [d for d in curr_char_divs if d]\n",
    "\n",
    "    # only get characters with valid pages (& no redirects)\n",
    "    for curr_char_div in curr_char_divs:\n",
    "        curr_char_url = \"{base}{suffix}\".format(base=base_url, suffix=curr_char_div.get('href'))\n",
    "        is_valid_page = requests.get(curr_char_url, allow_redirects=False).status_code == 200\n",
    "        if not is_valid_page:\n",
    "            continue\n",
    "        char_urls.append(curr_char_url)\n",
    "\n",
    "    next_page = curr_soup.find(\"a\", {\"class\": \"category-page__pagination-next\"})\n",
    "    if next_page:\n",
    "        next_url = next_page.get(\"href\")\n",
    "        char_urls.extend(get_character_pages(next_url, char_urls))\n",
    "        \n",
    "    return char_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6f6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, _ in categories.items():\n",
    "    category_url = base_url + _['path']\n",
    "    categories[name]['char_urls'] = get_character_pages(category_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f46e6",
   "metadata": {},
   "source": [
    "Get data\n",
    "\n",
    "* Deal format is array of characters\n",
    "* Target json - [{name:\"name\", img: \"img.png\", opts: {series:[\"a\"], affiliation:[\"b\"]}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88bb97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = dict()\n",
    "\n",
    "for category, _ in categories.items():\n",
    "    for char_url in _['char_urls']:\n",
    "        data = defaultdict(list)\n",
    "        curr_data = get_character_data(char_url, category)\n",
    "        if not curr_data:\n",
    "            continue\n",
    "            \n",
    "        name = \"{jp} ({en})\".format(jp=curr_data['name_jp'], en=curr_data['name_en'])\n",
    "        \n",
    "        data['img'] = re.search('(latest.+)', curr_data['img_url'], re.IGNORECASE).group(1)\n",
    "        #data['img'] = curr_data['img_url']\n",
    "        data['affiliation'].extend(curr_data['affiliation'])\n",
    "        data['series'].extend(curr_data['series'])\n",
    "        \n",
    "        data['affiliation'] = list(set(data['affiliation']))\n",
    "        data['series'] = list(set(data['series']))\n",
    "        \n",
    "        characters[name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a492f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "\n",
    "for character in characters:\n",
    "    curr = characters[character]\n",
    "    output_data.append(\n",
    "        dict(\n",
    "            name = character,\n",
    "            img = curr['img'],\n",
    "            opt = dict(series=curr['series'], affiliation=curr['affiliation'])\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27131011",
   "metadata": {},
   "source": [
    "Ended up downloading the images using wget ._."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23aaf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('img.txt', 'w') as f:\n",
    "#    for _ in output_data:\n",
    "#        f.write(_['img'])\n",
    "#        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bc521",
   "metadata": {},
   "source": [
    "Aspect ratio should be preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6abd0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:31: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-27-7112a47b7a50>:31: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n"
     ]
    }
   ],
   "source": [
    "def resizeAndPad(img, size, padColor=255):\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "\n",
    "    # interpolation method\n",
    "    if h > sh or w > sw: # shrinking image\n",
    "        interp = cv2.INTER_AREA\n",
    "\n",
    "    else: # stretching image\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    # aspect ratio of image\n",
    "    aspect = float(w)/h \n",
    "    saspect = float(sw)/sh\n",
    "\n",
    "    if (saspect > aspect) or ((saspect == 1) and (aspect <= 1)):  # new horizontal image\n",
    "        new_h = sh\n",
    "        new_w = np.round(new_h * aspect).astype(int)\n",
    "        pad_horz = float(sw - new_w) / 2\n",
    "        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
    "        pad_top, pad_bot = 0, 0\n",
    "\n",
    "    elif (saspect < aspect) or ((saspect == 1) and (aspect >= 1)):  # new vertical image\n",
    "        new_w = sw\n",
    "        new_h = np.round(float(new_w) / aspect).astype(int)\n",
    "        pad_vert = float(sh - new_h) / 2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "        pad_left, pad_right = 0, 0\n",
    "\n",
    "    # set pad color\n",
    "    if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n",
    "        padColor = [padColor]*3\n",
    "\n",
    "    # scale and pad\n",
    "    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
    "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
    "\n",
    "    return scaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53462f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
